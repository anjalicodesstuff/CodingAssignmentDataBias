# CodingAssignmentDataBias
Coding Assignment: Data Bias, I310D


Step 3: Testing

Below are a few of my hypotheses: 

The Perspective API will detect toxicity more accurately in shorter statements.
The Perspective API will be less likely to find toxicity in anti-male comments over anti-female comments.
The Perspective API will find comments with curse words more toxic. 

Step 4: Results & Analysis

What biases do you think might exist in the model based on intuitions or public documentation about how the model was created?
I think this model may be biased in terms of measuring what phrases/words are considered toxic. 
What were your results?

What theories do you have about why your results are what they are?



